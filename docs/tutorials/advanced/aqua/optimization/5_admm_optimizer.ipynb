{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMM Optimizer\n",
    "The latest version of this notebook is available on https://github.com/Qiskit/qiskit-iqx-tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain what problems this optimizer can solve\n",
    "- Introduce algorithm on high-level and refer to paper\n",
    "- explain that it takes a qubo_optimizer and cts_optimizer \n",
    "- Link to other optimizers (QAOA, Grover, ...) \n",
    "- Show Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ADMM Optimizer can solve classes of mixed-binary constrained optimization problems, hereafter (MBCO), which often appear in logistic, finance, and operation research. In particular, the ADMM Optimizer here designed can tackle the following optimization problem $(P)$:\n",
    "\n",
    "$$\n",
    "\\min_{x \\in \\mathcal{X},u\\in\\mathcal{U} \\subseteq \\mathbb{R}^l } \\quad q(x) + \\varphi(u),\n",
    "$$\n",
    "\n",
    "subject to the constraints:\n",
    "\n",
    "$$\n",
    "\\mathrm{s.t.:~} \\quad G x = b, \\quad  g(x) \\leq 0, \\quad \\ell(x, u) \\leq 0, \n",
    "$$\n",
    "\n",
    "with the corresponding functional assumptions.\n",
    "\n",
    "1. Function $q: \\mathbb{R}^n \\to \\mathbb{R}$ is quadratic, i.e., $q(x) = x^{\\intercal} Q x + a^{\\intercal} x$ for a given symmetric squared matrix $Q \\in \\mathbb{R}^n \\times \\mathbb{R}^n, Q = Q^{\\intercal}$, and vector $a \\in \\mathbb{R}^n$;\n",
    "2. The set $\\mathcal{X} = \\{0,1\\}^n = \\{x_{(i)} (1-x_{(i)}) = 0, \\forall i\\}$ enforces the binary constraints;\n",
    "3. Matrix $G\\in\\mathbb{R}^n \\times \\mathbb{R}^{n'}$, vector $b \\in \\mathbb{R}^{n'}$, and function $g: \\mathbb{R}^n \\to \\mathbb{R}$ is convex;\n",
    "4. Function $\\varphi: \\mathbb{R}^l \\to \\mathbb{R}$ is convex and $\\mathcal{U}$ is a convex set;\n",
    "5. Function $\\ell: \\mathbb{R}^n\\times  \\mathbb{R}^l \\to \\mathbb{R}$ is *jointly* convex in $x, u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to solve MBO problems, [1] proposed heuristics for $(P)$ based on the Alternating Direction Method of Multipliers (ADMM) [2]. ADMM is an operator splitting algorithm with a long history in convex optimization, and it is known to have residual, objective and dual variable convergence properties, provided that convexity assumptions are holding.\n",
    "\n",
    "The method of [1] (referred to as 3-ADMM-H) leverages the ADMM operator-splitting procedure to devise a decomposition for certain classes of MBOs into:\n",
    "- a QUBO subproblem to be solved by on the quantum device via variational algorithms, such as VQE or QAOA;\n",
    "- continuous convex constrained subproblem, which can be efficiently solved with classical optimization solvers.\n",
    "\n",
    "The algorithm 3-ADMM-H works as follows:\n",
    "\n",
    "0. Initialization phase (set the parameters and the QUBO and convex solvers);\n",
    "1. For each ADMM iterations ($k = 1, 2, \\ldots, $) till termination:\n",
    "    - Solve a properly defined QUBO subproblem (with a classical or quantum solver);\n",
    "    - Solve properly defined convex problems (with a classical solver);\n",
    "    - Update the dual variables.\n",
    "2. Return optimizers and cost.\n",
    "\n",
    "    \n",
    "A comprehensive discussion on the conditions for convergence, feasibility and optimality of the algorithm can be found in [1]. A variant with 2 ADMM blocks, namely a QUBO subproblem, and a continuous convex constrained subproblem, is also introduced in [1].\n",
    "\n",
    "## References\n",
    "\n",
    "[1] C. Gambella and A. Simonetto, *Multi-block ADMM  heuristics  for  mixed-binary  optimization, on  classical  and  quantum  computers,*  arXiv  preprint arXiv:2001.02069  (2020).\n",
    "\n",
    "[2] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, *Distributed  optimization  and statistical learning via the alternating direction method of  multipliers,*  Foundations  and  Trends in  Machine learning, 3, 1â€“122 (2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "First of all we load all the packages that we need:\n",
    "\n",
    "* Python 3.6 or greater is required;\n",
    "* CPLEX 12.10 or greater is required for the classical computations;\n",
    "* Latest Qiskit is required for the quantum computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cplex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-662c462c605a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcplex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparsePair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcplex_optimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCplexOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_algorithm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizationAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cplex'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from typing import List, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "from cplex import SparsePair\n",
    "from qiskit.optimization.algorithms.cplex_optimizer import CplexOptimizer\n",
    "from qiskit.optimization.algorithms.optimization_algorithm import OptimizationAlgorithm\n",
    "from qiskit.optimization.problems.optimization_problem import OptimizationProblem\n",
    "from qiskit.optimization.problems.variables import CPX_BINARY, CPX_CONTINUOUS\n",
    "from qiskit.optimization.results.optimization_result import OptimizationResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Classical Solution\n",
    "\n",
    "We test 3-ADMM-H algorithm on a simple Mixed-Binary Quadratic Problem with equality and inequality constraints (Example 6 reported in [1]). We first load necessary packages and populate with docplex. 3-ADMM-H needs a QUBO optimizer to solve the QUBO subproblem, and a continuous optimizer to solve the continuous convex constrained subproblem. We first solve the problem classically: a minimum eigensolver optimizer is used as QUBO optimizers, while Cplex is the continuous convex solver. 3-ADMM-H supports any other suitable solver available in Qiskit. For instance, VQE, QAOA, and Grover can be invoked as quantum solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model\n",
    "\n",
    "from qiskit.aqua.algorithms import NumPyMinimumEigensolver\n",
    "from qiskit.optimization import OptimizationProblem\n",
    "from qiskit.optimization.algorithms import MinimumEigenOptimizer, CplexOptimizer\n",
    "from qiskit.optimization.algorithms.admm_optimizer import ADMMParameters, ADMMOptimizer\n",
    "\n",
    "mdl = Model('ex6')\n",
    "\n",
    "v = mdl.binary_var(name='v')\n",
    "w = mdl.binary_var(name='w')\n",
    "t = mdl.binary_var(name='t')\n",
    "u = mdl.continuous_var(name='u')\n",
    "\n",
    "mdl.minimize(v + w + t + 5 * (u-2)**2)\n",
    "mdl.add_constraint(v + 2 * w + t + u <= 3, \"cons1\")\n",
    "mdl.add_constraint(v + w + t >= 1, \"cons2\")\n",
    "mdl.add_constraint(v + w == 1, \"cons3\")\n",
    "\n",
    "\n",
    "op = OptimizationProblem()\n",
    "op.from_docplex(mdl)\n",
    "\n",
    "qubo_optimizer = MinimumEigenOptimizer(NumPyMinimumEigensolver())\n",
    "# qubo_optimizer = CplexOptimizer()\n",
    "\n",
    "continuous_optimizer = CplexOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "The 3-ADMM-H are wrapped in class `ADMMParameters`. Customized parameter values can be set as arguments of the class. In this example, parameters $\\rho, \\beta$ are initialized to $1001$ and $1000$, respectively. The penalization `factor_c` of equality constraints $Gx = b$ is set to $900$. The tolerance `tol` for primal residual convergence is set to `1.e-6`. \n",
    "In this case, the 3-block implementation is guaranteed to converge for Theorem 4 of [1], because the inequality constraint with the continuous variable is always active. The 2-block implementation can be run by setting `three_block=False`, and practically converges to a feasible not optimal solution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admm_params = ADMMParameters(\n",
    "                             rho_initial=1001, beta=1000, factor_c=900,\n",
    "                             max_iter=100,  three_block=True, tol=1.e-6\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling 3-ADMM-H algorithm\n",
    "To invoke the 3-ADMM-H algorithm, an instance of the `ADMMOptimizer` class needs to be created. This takes ADMM-specific parameters and the subproblem optimizers separately into the constructor. The solution returned is an instance of `OptimizationResult` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ADMMOptimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ed76937355bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m solver = ADMMOptimizer(params=admm_params, qubo_optimizer=qubo_optimizer,\n\u001b[0m\u001b[1;32m      2\u001b[0m                              continuous_optimizer=continuous_optimizer)\n\u001b[1;32m      3\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ADMMOptimizer' is not defined"
     ]
    }
   ],
   "source": [
    "solver = ADMMOptimizer(params=admm_params, qubo_optimizer=qubo_optimizer,\n",
    "                             continuous_optimizer=continuous_optimizer)\n",
    "solution = solver.solve(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "The 3-ADMM-H solution can be then printed and visualized. The `x` attribute of the solution contains respectively, the\n",
    "values of the binary decision variables and the values of the continuous decision variables. The `fval` is the objective\n",
    "value of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"results\")\n",
    "print(\"x={}\".format(solution.x))\n",
    "print(\"fval={}\".format(solution.fval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution statistics can be accessed in the `state` field and visualized. We here display the convergence of 3-ADMM-H, in terms of primal residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.clf()\n",
    "plt.plot(solution.state.residuals)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Quantum Solution\n",
    "We now solve the same optimization problem with QAOA as QUBO optimizer, running on simulated quantum device. \n",
    "First, one need to select the classical optimizer of the eigensolver QAOA. Then, the simulation backened is set. Finally, \n",
    "the eigensolver is wrapped into the `MinimumEigenOptimizer` class. A new instance of `ADMMOptimizer` is populated with QAOA as QUBO optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'COBYLA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-829702686491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOBYLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmin_eigen_solver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQAOA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'statevector_simulator'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmin_eigen_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicAer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'COBYLA' is not defined"
     ]
    }
   ],
   "source": [
    "from qiskit import BasicAer\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "from qiskit.aqua.algorithms import QAOA,\n",
    "\n",
    "optimizer = COBYLA()\n",
    "min_eigen_solver = QAOA(optimizer=optimizer)\n",
    "backend = 'statevector_simulator'\n",
    "min_eigen_solver.quantum_instance = BasicAer.get_backend(backend)\n",
    "\n",
    "# construct minimum eigen optimizer\n",
    "min_eigen_optimizer = MinimumEigenOptimizer(min_eigen_solver)\n",
    "solver = ADMMOptimizer(params=admm_params, qubo_optimizer=min_eigen_optimizer,\n",
    "                             continuous_optimizer=continuous_optimizer)\n",
    "solution_q = solver.solve(op)\n",
    "\n",
    "print(\"results\")\n",
    "print(\"x={}\".format(solution_q.x))\n",
    "print(\"fval={}\".format(solution_q.fval))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(solution.state.merits)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localqiskit032020p36",
   "language": "python",
   "name": "localqiskit032020p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
